noam_wein,galart27
328238928,214953291

The two main regex's we used in this project are:
"[A-Za-z_][A-Za-z0-9_]*" for identifiers
"-?\\d+\\.\\d+" for doubles

The structure of the identifier regex is as follows:
1. [A-Za-z_] - The first character must be a letter (uppercase or lowercase) or an underscore.
2. [A-Za-z0-9_]* - The subsequent characters can be letters (uppercase or lowercase), digits, or underscores.
The asterisk (*) indicates that there can be zero or more of these characters.

The structure of the double regex is as follows:
1. -? - The number can optionally start with a negative sign (-). The question mark (?) indicates that the
preceding character (the negative sign) can appear zero or one time.
2. \\d+ - This part matches one or more digits (0-9). The plus sign (+) indicates that there must be at least
one digit.
3. \\. - This part matches the decimal point. The backslash (\\) is used to escape the dot (.) since a dot in
regex normally matches any character.
4. \\d+ - This part matches one or more digits (0-9) after the decimal point. Again, the plus sign (+)
indicates that there must be at least one digit.


The design of the project:
The project is divided into 4 packages:

1. lexer - This package contains the Lexer class, which is responsible for tokenizing the input string based on
the defined regex patterns.

2. parser - This package contains the Parser class, which takes the tokens generated by the Lexer and builds a
parse tree or abstract syntax tree (AST) based on the grammar rules.

3. ast - This package contains classes that represent the nodes of the abstract syntax tree (AST)
Each class corresponds to a different type of expression or statement in the language.

4. Semantic Analyzer - This package contains the SemanticAnalyzer class, which performs semantic analysis on the AST
to ensure that the program adheres to the language's semantic rules.
This includes type checking, scope resolution, and other semantic checks.
Each package has a specific role in the overall process of parsing and analyzing the input code, from
tokenization to semantic validation.